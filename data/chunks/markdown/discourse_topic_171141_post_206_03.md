---
chunk_id: discourse_topic_171141_post_206_03
source_url: https://discourse.onlinedegree.iitm.ac.in/t/171141/206
source_title: Tds-official-Project1-discrepencies
content_type: discourse
tokens: 252
username: thinkmachine
post_number: 206
topic_id: 171141
---

** endpoint to reset the agent’s conversation memory if the context window gets saturated.
**Deploying the entire project on a paid GCP VM Instance with a static IP**, utilizing my own OpenAI API key while keeping OpenAI’s API as a fallback in case AIPROXY ever gave up.

---

All this hard work evolved my project into something far beyond a simple Tool-Calling Agent—it essentially became a ReAct Principles based Computer-Using Agent capable of executing complex, non-linear workflows entirely within a container. And I’m not exaggerating: You could ask it to perform something like **hyperparameter tuning for a Random Forest Classifier, offloading the results locally on a JSON file and displaying its contents**, and it would do that for you—without **ever** declining the request. I like to think of it as a **terminal version of** OpenAI’s Computer-Using Agent.

Given all the effort, time, and money that went into this, it’s incredibly discouraging to see my project **naturally fail a sanity check (Docker image digest mismatch) (because of the aforesaid updates)** and not get evaluated as a result. This is not the kind of experience that encourages students to learn, experiment, and innovate.
