---
chunk_id: discourse_topic_164277_post_411_01
source_url: https://discourse.onlinedegree.iitm.ac.in/t/164277/411
source_title: Project 1 - LLM-based Automation Agent - Discussion Thread [TDS Jan 2025]
content_type: discourse
tokens: 343
username: Nelson
post_number: 411
topic_id: 164277
---

**[Discussion Image by Nelson]** This image depicts a student, Nelson, in the TDS Jan 2025 LLM discussion thread, running a curl command to interact with the aioproxy endpoint to obtain embeddings for the words "king" and "queen" using the "text-embedding-3-small" model. The command includes setting the AIPROXY_TOKEN via an environment variable and specifying the "Content-Type" as application/json. The output shows the successful execution of the curl command, returning a JSON response containing a list object with embedding data, including an index and an array of floating-point numbers representing the embedding vector. It appears to be a demonstration or a troubleshooting step related to obtaining embeddings as part of the LLM project. The successful JSON response indicates that the API call was correctly formatted and the student successfully retrieved the embeddings..workers.dev/openai/v1/embeddings` with the model set to `"text-embedding-3-small"` and the input as `["king", "queen"]`. It also sets the `AIPROXY_TOKEN` environment variable using `export`. The output displayed includes download/upload speed statistics and a JSON response containing a list of embeddings for the input words, shown as a series of floating-point numbers. This suggests the student is attempting to use the proxy to generate embeddings for the words "king" and "queen" and the image captures the successful retrieval of these embeddings." alt="image" data-base62-sha1="zI0bX2sssJ128w3Yb2Ypa83iAw" width="686" height="499" data-dominant-color="080808">image907Ã—661 26.5 KB
