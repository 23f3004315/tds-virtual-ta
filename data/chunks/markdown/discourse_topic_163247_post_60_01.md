---
chunk_id: discourse_topic_163247_post_60_01
source_url: https://discourse.onlinedegree.iitm.ac.in/t/163247/60
source_title: GA3 - Large Language Models - Discussion Thread [TDS Jan 2025]
content_type: discourse
tokens: 320
username: 24ds3000090
post_number: 60
topic_id: 163247
---

 Dear Sirs, I need help in solving this question. I have the same issue. I have tried tokenizer tool, tried writing request code but still couldnâ€™t get the correct answer. I have tried numerous time and ended up consuming lot of tokens . What should be the optimal approach in this question?

---

` "id": "chatcmpl-Aw7eXQ8hciiQ0ZedatQEifFGxnLhQ",
 "object": "chat.completion",
 "created": 1738415805,
 "model": "gpt-4o-mini-2024-07-18",
 "choices": [
 {
 "index": 0,
 "message": {
 "role": "assistant",
 "content": "The valid English words from the given list are:\n\n- a\n- I\n- o\n- t\n- U\n- w\n- y\n- z",
 "refusal": null
 },
 "logprobs": null,
 "finish_reason": "stop"
 }
 ],
 "usage": {
 "prompt_tokens": 532,
 "completion_tokens": 34,
 "total_tokens": 566,
 "prompt_tokens_details": {
 "cached_tokens": 0,
 "audio_tokens": 0
 }
 },
 "service_tier": "default",
 "system_fingerprint": "fp_bd83329f63",
 "monthlyCost": 0.01662212,
 "cost": 0.001863,
 "monthlyRequests": 41,
 "costError": "crypto.createHash is not a function"
}
`
