---
chunk_id: discourse_topic_164277_post_19_01
source_url: https://discourse.onlinedegree.iitm.ac.in/t/164277/19
source_title: Project 1 - LLM-based Automation Agent - Discussion Thread [TDS Jan 2025]
content_type: discourse
tokens: 1117
username: carlton
post_number: 19
topic_id: 164277
---

Project 1 deliverables are all that matter. How you accomplish them is not very relevant. The keys to a successful Project 1 are:

Deliverables,

and *an example* of the Evaluation has been provided.

If your project runs in accordance with the Evaluation methodology then it is considered.

---

**[Discussion Image by carlton]** This image shows instructions for Project 1 ("LLM-based Automation Agent") in a TDS student discussion thread. The "Deliverables" section outlines steps such as creating a GitHub repository with an MIT LICENSE, writing and testing code using POST /run?task=... and GET /read?path=... calls, creating a Dockerfile, publishing the Docker image to Docker Hub, and running the image via `podman run $IMAGE_NAME -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000` to serve the API at `http://localhost:8000/run?task=...` and `http://localhost:8000/read?path=...`. It also instructs students to submit links to their GitHub repo and Docker image via a Google Form. The "Note" section advises using the AIPROXY_TOKEN environment variable, using `os.environ["AIPROXY_TOKEN"]` in scripts, using the Al Proxy token with its $1 limit, sticking to GPT-4o-Mini, and keeping prompts short for /run and /read calls within 20 seconds. Finally, "Evaluation" is indicated as following. instead of committing the token to the repository. Finally, the note instructs to use GPT-4o-Mini and keep prompts short and concise to avoid timeouts." alt="Screenshot 2025-01-27 at 8.35.23 am" data-base62-sha1="alQUzS7pakBH4aCVJZXLB7NS2LG" width="500" height="500" srcset="**[Discussion Image by carlton]** This image shows part of the Project 1 instructions from the TDS course, specifically outlining "Deliverables" and important "Notes" for the students. The deliverable list includes creating a GitHub repository with an MIT license, writing and testing the code using `POST /run?task=...` and `GET /read?path=...`, creating a Dockerfile, publishing to Docker Hub, and ensuring the image runs via `podman run $IMAGE_NAME -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000` to serve the API at `http://localhost:8000/run?task=...` and `http://localhost:8000/read?path=...`. Students must submit their GitHub and Docker image URLs. The "Notes" section emphasizes using the `AIPROXY_TOKEN` environment variable and setting it with `os.environ ["AIPROXY_TOKEN"]`, avoiding committing the token, using their AI Proxy token with a $1 limit, sticking to the GPT-4o-Mini model, and keeping prompts short and concise with 20-second time limits for `/run` and `/read` calls. This context provides detailed guidance for the students to complete their first LLM-based automation agent project., **[Discussion Image by carlton]** This image shows instructor guidance on project deliverables and evaluation. The post outlines project requirements including creating a GitHub repository, adding an MIT LICENSE file, writing and testing code with POST and GET requests to /run and /read endpoints, creating a Dockerfile, publishing to Docker Hub, and running the image using podman with the specified AIPROXY_TOKEN environment variable and port mapping. Instructions emphasize the importance of using the AI Proxy token as an environment variable rather than committing it to the repository and suggest using `os.environ["AIPROXY_TOKEN"]` to set the token. The guidance specifies using GPT-4o-Mini as the LLM and keeping prompts short and concise, with calls to /run and /read completing within 20 seconds. 1.5x, **[Discussion Image by carlton]** This image from a student discussion thread provides instructions for a project involving an LLM-based automation agent, outlining deliverables and important notes. The deliverables include creating a GitHub repository, adding an MIT LICENSE, writing and testing code with POST and GET requests, creating and publishing a Dockerfile to Docker Hub, and ensuring the image runs via a `podman` command, which also sets the AIPROXY_TOKEN environment variable and maps ports for API access at `http://localhost:8000/run?task=...` and `http://localhost:8000/read?path=...`. Students must submit their GitHub and Docker image URLs in a Google Form. The "Note" section emphasizes the importance of using the AIPROXY_TOKEN environment variable without committing it to the repository, providing a Python example with `os.environ["AIPROXY_TOKEN"]`, highlighting the $1 limit for the Al Proxy token, specifying the use of GPT-4o-Mini, and advising to keep prompts short to ensure calls to `/run` and `/read` complete within 20 seconds, all indicating instructor-provided guidelines for the project. 2x" data-dominant-color="F3F2F2">Screenshot 2025-01-27 at 8.35.23 am1764Ã—1764 374 KB
